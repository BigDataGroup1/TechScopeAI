# TechScopeAI Source Code

This directory contains the core implementation of TechScopeAI's multi-agent system and data processing pipeline.

## ğŸ“ Structure

```
src/
â”œâ”€â”€ agents/          # Agent implementations
â”‚   â”œâ”€â”€ base_agent.py      # Base class for all agents
â”‚   â”œâ”€â”€ pitch_agent.py     # Pitch deck agent (3 modes)
â”‚   â”œâ”€â”€ competitive_agent.py
â”‚   â”œâ”€â”€ marketing_agent.py
â”‚   â”œâ”€â”€ patent_agent.py
â”‚   â”œâ”€â”€ policy_agent.py
â”‚   â”œâ”€â”€ team_agent.py
â”‚   â”œâ”€â”€ coordinator_agent.py
â”‚   â””â”€â”€ supervisor_agent.py
â”‚
â”œâ”€â”€ rag/             # RAG (Retrieval Augmented Generation) system
â”‚   â”œâ”€â”€ embedder.py        # Text embeddings (sentence-transformers/OpenAI)
â”‚   â”œâ”€â”€ vector_store.py    # FAISS vector database
â”‚   â”œâ”€â”€ retriever.py       # Document retrieval
â”‚   â”œâ”€â”€ collections.py     # Vector collections management
â”‚   â”œâ”€â”€ embeddings.py      # Embedding generation
â”‚   â”œâ”€â”€ retrieval.py       # Advanced retrieval
â”‚   â””â”€â”€ setup_rag.py       # RAG setup utilities
â”‚
â”œâ”€â”€ processors/      # Data processing pipeline
â”‚   â”œâ”€â”€ base_processor.py          # Base class with common utilities
â”‚   â”œâ”€â”€ competitive_processor.py   # Competitive analysis data
â”‚   â”œâ”€â”€ marketing_processor.py    # Marketing/ad copy data
â”‚   â”œâ”€â”€ ip_legal_processor.py     # IP/Legal/privacy data
â”‚   â”œâ”€â”€ policy_processor.py       # Policy documents
â”‚   â”œâ”€â”€ team_processor.py         # Team/job data
â”‚   â””â”€â”€ pitch_processor.py        # Pitch examples
â”‚
â”œâ”€â”€ api/             # Interfaces
â”‚   â””â”€â”€ chat_interface.py  # Streamlit web UI
â”‚
â”œâ”€â”€ data/            # User data storage
â”‚   â””â”€â”€ user_companies/    # Company details JSON files
â”‚
â”œâ”€â”€ utils/           # Utility modules
â”‚   â”œâ”€â”€ exporters.py      # Export functionality (PDF, PPTX)
â”‚   â””â”€â”€ image_fetcher.py  # Image fetching utilities
â”‚
â””â”€â”€ process_data.py  # Main data processing script
```

## ğŸ¤– Agents

### BaseAgent
Base class providing:
- RAG integration
- LLM query interface
- Response formatting

### PitchAgent
Specialized agent for pitch decks with 3 modes:

1. **Generate from Company Details**
   - Input: Company information (JSON)
   - Output: Complete pitch deck

2. **Generate from Outline**
   - Input: Outline with sections and notes
   - Output: Complete pitch deck

3. **Evaluate Pitch**
   - Input: Existing pitch text
   - Output: Evaluation with scores, strengths, weaknesses, improvements

### Other Agents
- **CompetitiveAgent**: Analyzes competitors and market positioning
- **MarketingAgent**: Creates marketing content and social media posts
- **PatentAgent**: Patent research, filing, and IP strategy
- **PolicyAgent**: Legal policies, compliance, and regulations
- **TeamAgent**: Team building, job descriptions, hiring
- **CoordinatorAgent**: Manages knowledge base and context
- **SupervisorAgent**: Routes queries to appropriate agents

## ğŸ” RAG System

### Embedder
- Generates text embeddings
- Supports: sentence-transformers (free) or OpenAI (paid)
- Default: `all-MiniLM-L6-v2` (384 dimensions)

### VectorStore
- FAISS-based vector database
- Stores embeddings and metadata
- Fast similarity search
- Also supports PostgreSQL with pgvector

### Retriever
- Semantic search over documents
- Returns relevant context with sources
- Filters by category

## ğŸ“Š Data Processing Pipeline

### Process All Datasets

```bash
# From project root
python -m src.process_data

# Or with custom paths
python -m src.process_data --raw-dir data/raw --output-dir data/processed
```

### Process Specific Agents

```bash
# Only competitive and marketing
python -m src.process_data --agents competitive marketing

# Only pitch data
python -m src.process_data --agents pitch
```

## What Each Processor Does

### Competitive Processor
- Processes startup/competitor datasets (CSV, JSON, JSONL)
- Extracts company information, descriptions, pitches
- Preserves full company context (one chunk per company)

### Marketing Processor
- Processes ad copy, taglines, creative content
- Handles Product Hunt taglines, ad creative datasets
- Processes review datasets (IMDB, Yelp, Amazon) for marketing insights

### IP/Legal Processor
- Processes PrivacyQA datasets (Q&A pairs)
- Processes OSS policy documents (markdown, text)
- Processes patent guide documents (HTML)

### Policy Processor
- Processes privacy policy documents (markdown, JSON)
- Handles annotated/compliance policy datasets
- Chunks by sections while preserving structure

### Team Processor
- Processes job skills datasets (CSV)
- Processes hiring guide articles (text, markdown)
- Extracts job descriptions, skills, responsibilities

### Pitch Processor
- Processes pitch examples (CSV, JSON)
- Processes blog articles (investor blogs, startup blogs, templates)
- Handles one-line pitches and full pitch examples

## Output Format

All processors output JSONL files with the following structure:

```json
{
  "text": "Chunk text content...",
  "metadata": {
    "agent": "competitive",
    "source": "data/raw/competitive/startup_data.csv",
    "source_file": "startup_data.csv",
    "chunk_id": "startup_data_0",
    "company_name": "Example Startup",
    "source_type": "csv",
    ...
  }
}
```

## Output Location

Processed data is saved to:
```
data/processed/
â”œâ”€â”€ competitive/
â”‚   â””â”€â”€ competitive_data.jsonl
â”œâ”€â”€ marketing/
â”‚   â””â”€â”€ marketing_data.jsonl
â”œâ”€â”€ ip_legal/
â”‚   â””â”€â”€ ip_legal_data.jsonl
â”œâ”€â”€ policy/
â”‚   â””â”€â”€ policy_data.jsonl
â”œâ”€â”€ team/
â”‚   â””â”€â”€ team_data.jsonl
â””â”€â”€ pitch/
    â””â”€â”€ pitch_data.jsonl
```

## ğŸ’¬ API

### Chat Interface (Streamlit)
- Web-based chat UI
- Company details form
- Real-time pitch generation/evaluation
- Source citations

## ğŸ“ Usage

### Initialize Agent

```python
from src.rag.embedder import Embedder
from src.rag.vector_store import VectorStore
from src.rag.retriever import Retriever
from src.agents.pitch_agent import PitchAgent

# Initialize RAG
embedder = Embedder(use_openai=False)
vector_store = VectorStore(category="pitch", dimension=embedder.get_embedding_dimension())
retriever = Retriever(vector_store, embedder)

# Initialize agent
agent = PitchAgent(retriever)
```

### Generate Pitch

```python
# From company details
company_data = {
    "company_name": "MyStartup",
    "industry": "SaaS",
    "problem": "...",
    "solution": "..."
}
response = agent.generate_from_details(company_data)
```

### Evaluate Pitch

```python
pitch_text = "My startup solves..."
response = agent.evaluate_pitch(pitch_text)
```

## ğŸ”§ Configuration

- **LLM Model**: Set in `PitchAgent.__init__(model="gpt-4-turbo-preview")`
- **Embeddings**: Set in `Embedder(use_openai=False)` for free embeddings
- **Top-K Retrieval**: Adjust in `retrieve_context(top_k=5)`

## ğŸ“š Data Flow

1. **User Query** â†’ Agent
2. **Agent** â†’ Retriever (semantic search)
3. **Retriever** â†’ VectorStore (find similar documents)
4. **Agent** â†’ LLM (generate response with context)
5. **Agent** â†’ User (formatted response with sources)

## ğŸš€ Next Steps

- See `SETUP_PITCH_AGENT.md` for agent setup instructions
- See `TECHSCOPE_AI_REBUILD_PLAN.md` for the full implementation plan
- After processing data, set up RAG infrastructure (ChromaDB or PostgreSQL with pgvector)
- Generate embeddings for all chunks
- Index into vector collections
